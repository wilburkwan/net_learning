{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPajl9pPclldP9C4JSzjztF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilburkwan/net_learning/blob/main/HW04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EnEmMso_991",
        "outputId": "8642ffbd-296b-4965-a5a8-043c3a7fcee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gspread pandas google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# PTT爬蟲 + 中文分析 + Gemini AI 整合系統\n",
        "# 自動化流程：爬蟲 → Sheet → 分析 → AI摘要\n",
        "# ========================================\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import jieba\n",
        "import jieba.posseg as pseg\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import time\n",
        "\n",
        "print(\"✅ 函式庫載入完成\")\n",
        "\n",
        "# ========================================\n",
        "# 第一部分：認證與全域設定\n",
        "# ========================================\n",
        "\n",
        "# Google 認證\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 設定參數\n",
        "GEMINI_API_KEY = \"AIzaSyBwzkoPUxcwmbZUfZHybZ0PyLuATLxf1g4\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# PTT 爬蟲設定\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
        "    'Cookie': 'over18=1'  # 繞過18歲確認\n",
        "}\n",
        "\n",
        "# 停用詞設定\n",
        "STOPWORDS = set(['的', '了', '是', '在', '我', '你', '他', '她', '之', '一個', '和',\n",
        "                 '討論', '分享', 'Re', 'Fw', '這', '那', '有', '也', '都', '就'])\n",
        "\n",
        "print(\"✅ 認證與設定完成\")\n",
        "\n",
        "# ========================================\n",
        "# 第二部分：PTT 爬蟲模組\n",
        "# ========================================\n",
        "\n",
        "def get_previous_page_url(soup):\n",
        "    \"\"\"獲取 PTT 上一頁連結\"\"\"\n",
        "    paging_div = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if paging_div:\n",
        "        buttons = paging_div.find_all('a')\n",
        "        if len(buttons) > 1:\n",
        "            prev_button = buttons[1]\n",
        "            if 'href' in prev_button.attrs and prev_button['href'] != '#':\n",
        "                return \"https://www.ptt.cc\" + prev_button['href']\n",
        "    return None\n",
        "\n",
        "def extract_index_from_url(url):\n",
        "    \"\"\"從 URL 提取頁碼\"\"\"\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except (IndexError, ValueError):\n",
        "        return None\n",
        "\n",
        "def crawl_ptt_board(board_name='movie', pages=5, delay=1):\n",
        "    \"\"\"\n",
        "    爬取 PTT 看板文章\n",
        "\n",
        "    參數:\n",
        "        board_name: 看板名稱 (預設: movie)\n",
        "        pages: 爬取頁數 (預設: 5)\n",
        "        delay: 每次請求間隔秒數 (預設: 1)\n",
        "\n",
        "    回傳:\n",
        "        DataFrame: 包含 title, author, date, href, page_index 欄位\n",
        "    \"\"\"\n",
        "    articles_data = []\n",
        "    base_url = f\"https://www.ptt.cc/bbs/{board_name}/index.html\"\n",
        "\n",
        "    try:\n",
        "        # 取得起始頁\n",
        "        response = requests.get(base_url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        current_url = get_previous_page_url(soup)\n",
        "\n",
        "        if not current_url:\n",
        "            print(\"❌ 無法取得起始頁面\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        start_index = extract_index_from_url(current_url)\n",
        "        print(f\"🚀 開始爬取 PTT {board_name} 版，從第 {start_index} 頁開始\")\n",
        "\n",
        "        # 批次爬取\n",
        "        for page_num in range(pages):\n",
        "            try:\n",
        "                page_index = start_index - page_num\n",
        "                url = f\"https://www.ptt.cc/bbs/{board_name}/index{page_index}.html\"\n",
        "                print(f\"⏳ 正在爬取第 {page_num + 1}/{pages} 頁: {url}\")\n",
        "\n",
        "                response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                article_list = soup.find_all('div', class_='r-ent')\n",
        "\n",
        "                for article in article_list:\n",
        "                    try:\n",
        "                        title_div = article.find('div', class_='title')\n",
        "                        title_tag = title_div.find('a') if title_div else None\n",
        "\n",
        "                        if title_tag and 'href' in title_tag.attrs:\n",
        "                            title = title_tag.text.strip()\n",
        "                            href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "                        else:\n",
        "                            title = title_div.text.strip() if title_div else \"(無標題)\"\n",
        "                            href = \"N/A\"\n",
        "\n",
        "                        author_div = article.find('div', class_='author')\n",
        "                        author = author_div.text.strip() if author_div else \"(匿名)\"\n",
        "\n",
        "                        date_div = article.find('div', class_='date')\n",
        "                        date = date_div.text.strip() if date_div else \"(無日期)\"\n",
        "\n",
        "                        articles_data.append({\n",
        "                            'title': title,\n",
        "                            'date': date,\n",
        "                            'author': author,\n",
        "                            'href': href,\n",
        "                            'page_index': page_index\n",
        "                        })\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "\n",
        "                print(f\"✅ 第 {page_num + 1} 頁完成，取得 {len(article_list)} 篇文章\")\n",
        "                time.sleep(delay)  # 避免請求過快\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"❌ 第 {page_num + 1} 頁爬取失敗: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"🎉 爬蟲完成！共收集 {len(articles_data)} 篇文章\")\n",
        "        return pd.DataFrame(articles_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 爬蟲初始化失敗: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ========================================\n",
        "# 第三部分：Google Sheet 讀寫模組\n",
        "# ========================================\n",
        "\n",
        "def write_to_sheet(df, sheet_url, worksheet_name='爬蟲資料'):\n",
        "    \"\"\"將 DataFrame 寫入 Google Sheet\"\"\"\n",
        "    try:\n",
        "        # 開啟試算表\n",
        "        try:\n",
        "            sh = gc.open_by_url(sheet_url)\n",
        "        except:\n",
        "            # 如果試算表不存在，創建新的\n",
        "            sh = gc.create(worksheet_name)\n",
        "            print(f\"📝 已建立新試算表: {sh.url}\")\n",
        "\n",
        "        # 檢查工作表是否存在\n",
        "        try:\n",
        "            ws = sh.worksheet(worksheet_name)\n",
        "            ws.clear()  # 清空現有資料\n",
        "        except:\n",
        "            ws = sh.add_worksheet(title=worksheet_name, rows=str(len(df)+10), cols=str(len(df.columns)+5))\n",
        "\n",
        "        # 寫入資料\n",
        "        ws.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "        print(f\"✅ 已將 {len(df)} 筆資料寫入「{worksheet_name}」工作表\")\n",
        "        return sh.url\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 寫入 Google Sheet 失敗: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_from_sheet(sheet_url, worksheet_name='爬蟲資料'):\n",
        "    \"\"\"從 Google Sheet 讀取資料\"\"\"\n",
        "    try:\n",
        "        sh = gc.open_by_url(sheet_url)\n",
        "        ws = sh.worksheet(worksheet_name)\n",
        "        df = pd.DataFrame(ws.get_all_records())\n",
        "        print(f\"✅ 已讀取 {len(df)} 筆資料\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 讀取 Google Sheet 失敗: {e}\")\n",
        "        return None\n",
        "\n",
        "# ========================================\n",
        "# 第四部分：中文斷詞與 TF-IDF 分析模組\n",
        "# ========================================\n",
        "\n",
        "def analyze_text(df, text_column='title', topN=10):\n",
        "    \"\"\"\n",
        "    執行文本分析：詞頻統計 + TF-IDF\n",
        "\n",
        "    參數:\n",
        "        df: DataFrame\n",
        "        text_column: 要分析的文字欄位\n",
        "        topN: 回傳前 N 名結果\n",
        "\n",
        "    回傳:\n",
        "        tuple: (詞頻統計列表, TF-IDF排名列表)\n",
        "    \"\"\"\n",
        "    print(f\"\\n🔍 開始分析「{text_column}」欄位...\")\n",
        "\n",
        "    # 過濾空值\n",
        "    texts = df[text_column].dropna().astype(str).tolist()\n",
        "\n",
        "    if not texts:\n",
        "        print(\"❌ 沒有可分析的文字\")\n",
        "        return [], []\n",
        "\n",
        "    # === 詞頻統計 ===\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        # 清理文字\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        # 斷詞\n",
        "        words = jieba.lcut(cleaned_text)\n",
        "        # 過濾\n",
        "        filtered_words = [w.strip() for w in words\n",
        "                         if w.strip() and len(w.strip()) > 1 and w.strip() not in STOPWORDS]\n",
        "        all_words.extend(filtered_words)\n",
        "\n",
        "    freq_counter = Counter(all_words)\n",
        "    top_freq = freq_counter.most_common(topN)\n",
        "\n",
        "    print(f\"✅ 詞頻統計完成，共 {len(freq_counter)} 個不重複詞彙\")\n",
        "\n",
        "    # === TF-IDF 分析 ===\n",
        "    try:\n",
        "        # 準備文檔\n",
        "        documents = []\n",
        "        for text in texts:\n",
        "            cleaned_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "            words = jieba.lcut(cleaned_text)\n",
        "            filtered_words = [w.strip() for w in words\n",
        "                             if w.strip() and len(w.strip()) > 1 and w.strip() not in STOPWORDS]\n",
        "            documents.append(\" \".join(filtered_words))\n",
        "\n",
        "        # 計算 TF-IDF\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        # 計算平均權重\n",
        "        avg_scores = tfidf_matrix.mean(axis=0).A1\n",
        "        tfidf_rank = sorted(zip(feature_names, avg_scores),\n",
        "                           key=lambda x: x[1], reverse=True)[:topN]\n",
        "\n",
        "        print(f\"✅ TF-IDF 分析完成\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ TF-IDF 分析失敗: {e}\")\n",
        "        tfidf_rank = []\n",
        "\n",
        "    return top_freq, tfidf_rank\n",
        "\n",
        "# ========================================\n",
        "# 第五部分：Gemini AI 摘要生成模組\n",
        "# ========================================\n",
        "\n",
        "def generate_gemini_summary(hot_words, sample_texts, analysis_type=\"文章標題\"):\n",
        "    \"\"\"\n",
        "    使用 Gemini AI 生成分析摘要\n",
        "\n",
        "    參數:\n",
        "        hot_words: 熱門關鍵詞列表\n",
        "        sample_texts: 部分文本樣本\n",
        "        analysis_type: 分析類型描述\n",
        "\n",
        "    回傳:\n",
        "        str: AI 生成的摘要\n",
        "    \"\"\"\n",
        "    print(\"\\n🤖 開始生成 Gemini AI 摘要...\")\n",
        "\n",
        "    # 準備 prompt\n",
        "    hot_words_str = \"、\".join([f\"{word}({count}次)\" for word, count in hot_words[:10]])\n",
        "    sample_str = \"\\n\".join([f\"- {text[:100]}\" for text in sample_texts[:5]])\n",
        "\n",
        "    prompt = f\"\"\"你是一位專業的資料分析師，負責分析 PTT 論壇的{analysis_type}資料。\n",
        "\n",
        "**熱門關鍵詞統計：**\n",
        "{hot_words_str}\n",
        "\n",
        "**部分{analysis_type}樣本：**\n",
        "{sample_str}\n",
        "\n",
        "**請進行以下分析：**\n",
        "1. 用5句話總結當前討論的主要趨勢與現象\n",
        "2. 提供一段120字的繁體中文專業結論摘要\n",
        "3. 指出討論的熱點話題與值得關注的方向\n",
        "\n",
        "請直接提供分析結果，不要包含分析步驟說明。使用繁體中文回答。\"\"\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        if hasattr(response, 'text'):\n",
        "            print(\"✅ AI 摘要生成完成\")\n",
        "            return response.text\n",
        "        else:\n",
        "            return \"❌ AI 無法生成摘要\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Gemini API 呼叫失敗: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "# ========================================\n",
        "# 第六部分：統計結果回寫模組\n",
        "# ========================================\n",
        "\n",
        "def write_analysis_to_sheet(freq_stats, tfidf_stats, ai_summary,\n",
        "                            sheet_url, worksheet_name='分析統計'):\n",
        "    \"\"\"將分析結果回寫到 Google Sheet\"\"\"\n",
        "    try:\n",
        "        sh = gc.open_by_url(sheet_url)\n",
        "\n",
        "        # 建立或清空工作表\n",
        "        try:\n",
        "            ws = sh.worksheet(worksheet_name)\n",
        "            ws.clear()\n",
        "        except:\n",
        "            ws = sh.add_worksheet(title=worksheet_name, rows=\"100\", cols=\"10\")\n",
        "\n",
        "        # 寫入時間戳記\n",
        "        from datetime import datetime\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        ws.update('A1', [[f\"分析報告 - 生成時間：{timestamp}\"]])\n",
        "\n",
        "        # 寫入詞頻統計\n",
        "        ws.update('A3', [[\"📊 詞頻統計（前10名）\", \"\", \"\"]])\n",
        "        ws.update('A4', [[\"排名\", \"關鍵詞\", \"出現次數\"]])\n",
        "        for i, (word, count) in enumerate(freq_stats[:10], start=1):\n",
        "            ws.update(f'A{4+i}', [[i, word, count]])\n",
        "\n",
        "        # 寫入 TF-IDF 分析\n",
        "        tfidf_start_row = 4 + len(freq_stats[:10]) + 3\n",
        "        ws.update(f'A{tfidf_start_row}', [[\"📈 TF-IDF 重要詞彙分析\", \"\"]])\n",
        "        ws.update(f'A{tfidf_start_row+1}', [[\"關鍵詞\", \"TF-IDF 分數\"]])\n",
        "        for i, (word, score) in enumerate(tfidf_stats[:10], start=1):\n",
        "            ws.update(f'A{tfidf_start_row+1+i}', [[word, round(score, 4)]])\n",
        "\n",
        "        # 寫入 AI 摘要\n",
        "        summary_row = tfidf_start_row + len(tfidf_stats[:10]) + 4\n",
        "        ws.update(f'A{summary_row}', [[\"🤖 Gemini AI 深度洞察分析\"]])\n",
        "        ws.update(f'A{summary_row+1}', [[ai_summary]])\n",
        "\n",
        "        print(f\"✅ 統計結果已寫入「{worksheet_name}」工作表\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ 回寫統計失敗: {e}\")\n",
        "        return False\n",
        "\n",
        "# ========================================\n",
        "# 第七部分：完整流程整合\n",
        "# ========================================\n",
        "\n",
        "def full_automation_pipeline(board_name, pages, topN, sheet_url=None):\n",
        "    \"\"\"\n",
        "    完整自動化流程：爬蟲 → Sheet → 分析 → AI → 回寫\n",
        "\n",
        "    參數:\n",
        "        board_name: PTT 看板名稱\n",
        "        pages: 爬取頁數\n",
        "        topN: 顯示前 N 名關鍵詞\n",
        "        sheet_url: Google Sheet URL (可選)\n",
        "\n",
        "    回傳:\n",
        "        str: 執行結果報告\n",
        "    \"\"\"\n",
        "    report = []\n",
        "    report.append(\"=\" * 60)\n",
        "    report.append(\"🚀 PTT 爬蟲與文本分析系統 - 執行開始\")\n",
        "    report.append(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    try:\n",
        "        # ===== 步驟 1: 爬取 PTT 資料 =====\n",
        "        report.append(\"📍 步驟 1/5：爬取 PTT 資料\")\n",
        "        df_articles = crawl_ptt_board(board_name=board_name, pages=pages, delay=1)\n",
        "\n",
        "        if df_articles.empty:\n",
        "            return \"\\n\".join(report) + \"\\n❌ 爬蟲失敗，無法繼續執行\"\n",
        "\n",
        "        report.append(f\"✅ 成功爬取 {len(df_articles)} 篇文章\\n\")\n",
        "\n",
        "        # ===== 步驟 2: 寫入 Google Sheet =====\n",
        "        report.append(\"📍 步驟 2/5：寫入 Google Sheet\")\n",
        "        if not sheet_url:\n",
        "            # 創建新試算表\n",
        "            new_sheet = gc.create(f'PTT_{board_name}_分析')\n",
        "            sheet_url = new_sheet.url\n",
        "            report.append(f\"📝 已建立新試算表：{sheet_url}\")\n",
        "\n",
        "        result_url = write_to_sheet(df_articles, sheet_url, worksheet_name='爬蟲資料')\n",
        "        if result_url:\n",
        "            report.append(f\"✅ 資料已寫入：{result_url}\\n\")\n",
        "        else:\n",
        "            report.append(\"⚠️ 寫入失敗，但繼續執行分析\\n\")\n",
        "\n",
        "        # ===== 步驟 3: 從 Sheet 讀取並分析 =====\n",
        "        report.append(\"📍 步驟 3/5：文本分析（詞頻 + TF-IDF）\")\n",
        "        freq_stats, tfidf_stats = analyze_text(df_articles, text_column='title', topN=topN)\n",
        "\n",
        "        if freq_stats:\n",
        "            report.append(f\"✅ 分析完成，發現 {len(freq_stats)} 個熱門詞彙\\n\")\n",
        "        else:\n",
        "            return \"\\n\".join(report) + \"\\n❌ 分析失敗\"\n",
        "\n",
        "        # ===== 步驟 4: Gemini AI 生成摘要 =====\n",
        "        report.append(\"📍 步驟 4/5：Gemini AI 生成洞察摘要\")\n",
        "        sample_texts = df_articles['title'].dropna().astype(str).tolist()\n",
        "        ai_summary = generate_gemini_summary(freq_stats, sample_texts, analysis_type=\"文章標題\")\n",
        "        report.append(\"✅ AI 摘要生成完成\\n\")\n",
        "\n",
        "        # ===== 步驟 5: 回寫統計結果 =====\n",
        "        report.append(\"📍 步驟 5/5：回寫分析統計\")\n",
        "        if sheet_url:\n",
        "            write_analysis_to_sheet(freq_stats, tfidf_stats, ai_summary,\n",
        "                                   sheet_url, worksheet_name='分析統計')\n",
        "            report.append(f\"✅ 統計結果已回寫至試算表\\n\")\n",
        "\n",
        "        # ===== 生成最終報告 =====\n",
        "        report.append(\"=\" * 60)\n",
        "        report.append(\"📊 分析結果摘要\")\n",
        "        report.append(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "        # 熱門關鍵詞\n",
        "        report.append(\"### 🔥 熱門關鍵詞統計（前10名）\")\n",
        "        for i, (word, count) in enumerate(freq_stats[:10], 1):\n",
        "            report.append(f\"{i}. **{word}** - {count} 次\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # TF-IDF 重要詞彙\n",
        "        report.append(\"### 📈 TF-IDF 重要詞彙（前10名）\")\n",
        "        for i, (word, score) in enumerate(tfidf_stats[:10], 1):\n",
        "            report.append(f\"{i}. **{word}** - {score:.4f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # AI 洞察\n",
        "        report.append(\"### 🤖 Gemini AI 深度洞察\")\n",
        "        report.append(ai_summary)\n",
        "        report.append(\"\")\n",
        "\n",
        "        # 資料概覽\n",
        "        report.append(\"### 📋 資料概覽\")\n",
        "        report.append(f\"- 看板名稱：**{board_name}**\")\n",
        "        report.append(f\"- 文章數量：**{len(df_articles)}** 篇\")\n",
        "        report.append(f\"- 分析時間：**{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}**\")\n",
        "        if sheet_url:\n",
        "            report.append(f\"- Google Sheet：[點此查看]({sheet_url})\")\n",
        "\n",
        "        report.append(\"\\n\" + \"=\" * 60)\n",
        "        report.append(\"🎉 所有流程執行完成！\")\n",
        "        report.append(\"=\" * 60)\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "    except Exception as e:\n",
        "        report.append(f\"\\n❌ 執行過程發生錯誤：{e}\")\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "# ========================================\n",
        "# 第八部分：Gradio UI 介面\n",
        "# ========================================\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"建立 Gradio 使用者介面\"\"\"\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"PTT 爬蟲分析系統\") as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # 🎯 PTT 爬蟲與文本分析系統\n",
        "        **完整自動化流程：** PTT爬蟲 → Google Sheet → 中文斷詞 → TF-IDF分析 → Gemini AI洞察 → 統計回寫\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### 📝 參數設定\")\n",
        "                board_input = gr.Textbox(\n",
        "                    label=\"🎬 PTT 看板名稱\",\n",
        "                    value=\"movie\",\n",
        "                    placeholder=\"例如：movie, Gossiping, Tech_Job\",\n",
        "                    info=\"輸入要爬取的 PTT 看板名稱\"\n",
        "                )\n",
        "                pages_input = gr.Slider(\n",
        "                    minimum=1,\n",
        "                    maximum=20,\n",
        "                    value=5,\n",
        "                    step=1,\n",
        "                    label=\"📄 爬取頁數\",\n",
        "                    info=\"每頁約 20 篇文章\"\n",
        "                )\n",
        "                topN_input = gr.Slider(\n",
        "                    minimum=5,\n",
        "                    maximum=30,\n",
        "                    value=10,\n",
        "                    step=1,\n",
        "                    label=\"🔢 顯示前 N 名關鍵詞\"\n",
        "                )\n",
        "                sheet_url_input = gr.Textbox(\n",
        "                    label=\"🔗 Google Sheet URL（選填）\",\n",
        "                    placeholder=\"留空則自動建立新試算表\",\n",
        "                    info=\"若要使用現有試算表，請貼上完整 URL\"\n",
        "                )\n",
        "\n",
        "                submit_btn = gr.Button(\n",
        "                    \"🚀 開始執行完整分析\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### 📊 執行結果\")\n",
        "                output_box = gr.Textbox(\n",
        "                    label=\"分析報告\",\n",
        "                    lines=25,\n",
        "                    max_lines=30,\n",
        "                    show_copy_button=True\n",
        "                )\n",
        "\n",
        "        # 按鈕事件綁定\n",
        "        submit_btn.click(\n",
        "            fn=full_automation_pipeline,\n",
        "            inputs=[board_input, pages_input, topN_input, sheet_url_input],\n",
        "            outputs=output_box\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        ### 📌 使用說明\n",
        "        1. **Gemini API Key**：請先在程式碼中填入您的 API Key（前往 [Google AI Studio](https://makersuite.google.com/app/apikey) 申請）\n",
        "        2. **看板名稱**：輸入要分析的 PTT 看板（例如：movie、Gossiping、Stock）\n",
        "        3. **頁數設定**：建議 5-10 頁，避免爬取過多導致執行時間過長\n",
        "        4. **執行流程**：點擊「開始執行」後，系統會自動完成所有步驟\n",
        "        5. **查看結果**：分析完成後會在右側顯示報告，並自動寫入 Google Sheet\n",
        "\n",
        "        ### ⚠️ 注意事項\n",
        "        - 請遵守 PTT 使用規範，適度使用爬蟲功能\n",
        "        - 爬取速度已設定延遲，避免對伺服器造成負擔\n",
        "        - 確保已完成 Google Colab 的授權認證\n",
        "        - Gemini API 有使用額度限制，請注意配額使用狀況\n",
        "\n",
        "        ### 🔧 系統架構\n",
        "        | 模組 | 技術 | 功能 |\n",
        "        |------|------|------|\n",
        "        | 爬蟲 | requests + BeautifulSoup | 批次爬取文章資料 |\n",
        "        | 儲存 | gspread + OAuth2 | Google Sheet 讀寫 |\n",
        "        | 斷詞 | jieba | 中文文本斷詞 |\n",
        "        | 分析 | scikit-learn TF-IDF | 關鍵詞提取 |\n",
        "        | AI | Gemini API | 智能摘要生成 |\n",
        "        | UI | Gradio | 互動式介面 |\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# ========================================\n",
        "# 主程式執行區\n",
        "# ========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🎯 PTT 爬蟲與文本分析系統\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # 啟動 Gradio 介面\n",
        "    demo = create_gradio_interface()\n",
        "    demo.launch(\n",
        "        share=True,  # 產生公開連結\n",
        "        debug=True   # 開啟除錯模式\n",
        "    )\n",
        "\n",
        "    print(\"\\n✅ Gradio 介面已啟動\")\n",
        "    print(\"📱 可透過產生的連結在任何裝置上使用\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8MrqifIuwmSh",
        "outputId": "bfb0f9c8-9868-487d-f2d3-6fdd19462bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 函式庫載入完成\n",
            "✅ 認證與設定完成\n",
            "\n",
            "============================================================\n",
            "🎯 PTT 爬蟲與文本分析系統\n",
            "============================================================\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://69a63e355eae9babf8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://69a63e355eae9babf8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 開始爬取 PTT movie 版，從第 10809 頁開始\n",
            "⏳ 正在爬取第 1/5 頁: https://www.ptt.cc/bbs/movie/index10809.html\n",
            "✅ 第 1 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 2/5 頁: https://www.ptt.cc/bbs/movie/index10808.html\n",
            "✅ 第 2 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 3/5 頁: https://www.ptt.cc/bbs/movie/index10807.html\n",
            "✅ 第 3 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 4/5 頁: https://www.ptt.cc/bbs/movie/index10806.html\n",
            "✅ 第 4 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 5/5 頁: https://www.ptt.cc/bbs/movie/index10805.html\n",
            "✅ 第 5 頁完成，取得 20 篇文章\n",
            "🎉 爬蟲完成！共收集 100 篇文章\n",
            "✅ 已將 100 筆資料寫入「爬蟲資料」工作表\n",
            "\n",
            "🔍 開始分析「title」欄位...\n",
            "✅ 詞頻統計完成，共 428 個不重複詞彙\n",
            "✅ TF-IDF 分析完成\n",
            "\n",
            "🤖 開始生成 Gemini AI 摘要...\n",
            "✅ AI 摘要生成完成\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3374716129.py:340: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A1', [[f\"分析報告 - 生成時間：{timestamp}\"]])\n",
            "/tmp/ipython-input-3374716129.py:343: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A3', [[\"📊 詞頻統計（前10名）\", \"\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:344: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A4', [[\"排名\", \"關鍵詞\", \"出現次數\"]])\n",
            "/tmp/ipython-input-3374716129.py:346: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{4+i}', [[i, word, count]])\n",
            "/tmp/ipython-input-3374716129.py:350: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row}', [[\"📈 TF-IDF 重要詞彙分析\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:351: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1}', [[\"關鍵詞\", \"TF-IDF 分數\"]])\n",
            "/tmp/ipython-input-3374716129.py:353: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1+i}', [[word, round(score, 4)]])\n",
            "/tmp/ipython-input-3374716129.py:357: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row}', [[\"🤖 Gemini AI 深度洞察分析\"]])\n",
            "/tmp/ipython-input-3374716129.py:358: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row+1}', [[ai_summary]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 統計結果已寫入「分析統計」工作表\n",
            "🚀 開始爬取 PTT movie 版，從第 10809 頁開始\n",
            "⏳ 正在爬取第 1/5 頁: https://www.ptt.cc/bbs/movie/index10809.html\n",
            "✅ 第 1 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 2/5 頁: https://www.ptt.cc/bbs/movie/index10808.html\n",
            "✅ 第 2 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 3/5 頁: https://www.ptt.cc/bbs/movie/index10807.html\n",
            "✅ 第 3 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 4/5 頁: https://www.ptt.cc/bbs/movie/index10806.html\n",
            "✅ 第 4 頁完成，取得 20 篇文章\n",
            "⏳ 正在爬取第 5/5 頁: https://www.ptt.cc/bbs/movie/index10805.html\n",
            "✅ 第 5 頁完成，取得 20 篇文章\n",
            "🎉 爬蟲完成！共收集 100 篇文章\n",
            "✅ 已將 100 筆資料寫入「爬蟲資料」工作表\n",
            "\n",
            "🔍 開始分析「title」欄位...\n",
            "✅ 詞頻統計完成，共 428 個不重複詞彙\n",
            "✅ TF-IDF 分析完成\n",
            "\n",
            "🤖 開始生成 Gemini AI 摘要...\n",
            "✅ AI 摘要生成完成\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3374716129.py:340: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A1', [[f\"分析報告 - 生成時間：{timestamp}\"]])\n",
            "/tmp/ipython-input-3374716129.py:343: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A3', [[\"📊 詞頻統計（前10名）\", \"\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:344: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A4', [[\"排名\", \"關鍵詞\", \"出現次數\"]])\n",
            "/tmp/ipython-input-3374716129.py:346: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{4+i}', [[i, word, count]])\n",
            "/tmp/ipython-input-3374716129.py:350: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row}', [[\"📈 TF-IDF 重要詞彙分析\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:351: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1}', [[\"關鍵詞\", \"TF-IDF 分數\"]])\n",
            "/tmp/ipython-input-3374716129.py:353: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1+i}', [[word, round(score, 4)]])\n",
            "/tmp/ipython-input-3374716129.py:357: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row}', [[\"🤖 Gemini AI 深度洞察分析\"]])\n",
            "/tmp/ipython-input-3374716129.py:358: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row+1}', [[ai_summary]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 統計結果已寫入「分析統計」工作表\n"
          ]
        }
      ]
    }
  ]
}