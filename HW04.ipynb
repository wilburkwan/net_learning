{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPajl9pPclldP9C4JSzjztF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilburkwan/net_learning/blob/main/HW04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EnEmMso_991",
        "outputId": "8642ffbd-296b-4965-a5a8-043c3a7fcee5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gspread in /usr/local/lib/python3.12/dist-packages (6.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.12/dist-packages (0.8.5)\n",
            "Requirement already satisfied: google-auth>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from gspread) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from gspread) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.25.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.184.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (2.11.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from google-generativeai) (4.15.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-api-core->google-generativeai) (2.32.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.12.0->gspread) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.75.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.10.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gspread pandas google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# PTTçˆ¬èŸ² + ä¸­æ–‡åˆ†æ + Gemini AI æ•´åˆç³»çµ±\n",
        "# è‡ªå‹•åŒ–æµç¨‹ï¼šçˆ¬èŸ² â†’ Sheet â†’ åˆ†æ â†’ AIæ‘˜è¦\n",
        "# ========================================\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import jieba\n",
        "import jieba.posseg as pseg\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import gradio as gr\n",
        "import google.generativeai as genai\n",
        "import gspread\n",
        "from google.colab import auth\n",
        "from google.auth import default\n",
        "import time\n",
        "\n",
        "print(\"âœ… å‡½å¼åº«è¼‰å…¥å®Œæˆ\")\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬ä¸€éƒ¨åˆ†ï¼šèªè­‰èˆ‡å…¨åŸŸè¨­å®š\n",
        "# ========================================\n",
        "\n",
        "# Google èªè­‰\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# è¨­å®šåƒæ•¸\n",
        "GEMINI_API_KEY = \"AIzaSyBwzkoPUxcwmbZUfZHybZ0PyLuATLxf1g4\"\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# PTT çˆ¬èŸ²è¨­å®š\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',\n",
        "    'Cookie': 'over18=1'  # ç¹é18æ­²ç¢ºèª\n",
        "}\n",
        "\n",
        "# åœç”¨è©è¨­å®š\n",
        "STOPWORDS = set(['çš„', 'äº†', 'æ˜¯', 'åœ¨', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'ä¹‹', 'ä¸€å€‹', 'å’Œ',\n",
        "                 'è¨è«–', 'åˆ†äº«', 'Re', 'Fw', 'é€™', 'é‚£', 'æœ‰', 'ä¹Ÿ', 'éƒ½', 'å°±'])\n",
        "\n",
        "print(\"âœ… èªè­‰èˆ‡è¨­å®šå®Œæˆ\")\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬äºŒéƒ¨åˆ†ï¼šPTT çˆ¬èŸ²æ¨¡çµ„\n",
        "# ========================================\n",
        "\n",
        "def get_previous_page_url(soup):\n",
        "    \"\"\"ç²å– PTT ä¸Šä¸€é é€£çµ\"\"\"\n",
        "    paging_div = soup.find('div', class_='btn-group btn-group-paging')\n",
        "    if paging_div:\n",
        "        buttons = paging_div.find_all('a')\n",
        "        if len(buttons) > 1:\n",
        "            prev_button = buttons[1]\n",
        "            if 'href' in prev_button.attrs and prev_button['href'] != '#':\n",
        "                return \"https://www.ptt.cc\" + prev_button['href']\n",
        "    return None\n",
        "\n",
        "def extract_index_from_url(url):\n",
        "    \"\"\"å¾ URL æå–é ç¢¼\"\"\"\n",
        "    try:\n",
        "        index_str = url.split('index')[1].split('.html')[0]\n",
        "        return int(index_str)\n",
        "    except (IndexError, ValueError):\n",
        "        return None\n",
        "\n",
        "def crawl_ptt_board(board_name='movie', pages=5, delay=1):\n",
        "    \"\"\"\n",
        "    çˆ¬å– PTT çœ‹æ¿æ–‡ç« \n",
        "\n",
        "    åƒæ•¸:\n",
        "        board_name: çœ‹æ¿åç¨± (é è¨­: movie)\n",
        "        pages: çˆ¬å–é æ•¸ (é è¨­: 5)\n",
        "        delay: æ¯æ¬¡è«‹æ±‚é–“éš”ç§’æ•¸ (é è¨­: 1)\n",
        "\n",
        "    å›å‚³:\n",
        "        DataFrame: åŒ…å« title, author, date, href, page_index æ¬„ä½\n",
        "    \"\"\"\n",
        "    articles_data = []\n",
        "    base_url = f\"https://www.ptt.cc/bbs/{board_name}/index.html\"\n",
        "\n",
        "    try:\n",
        "        # å–å¾—èµ·å§‹é \n",
        "        response = requests.get(base_url, headers=HEADERS, timeout=10)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        current_url = get_previous_page_url(soup)\n",
        "\n",
        "        if not current_url:\n",
        "            print(\"âŒ ç„¡æ³•å–å¾—èµ·å§‹é é¢\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        start_index = extract_index_from_url(current_url)\n",
        "        print(f\"ğŸš€ é–‹å§‹çˆ¬å– PTT {board_name} ç‰ˆï¼Œå¾ç¬¬ {start_index} é é–‹å§‹\")\n",
        "\n",
        "        # æ‰¹æ¬¡çˆ¬å–\n",
        "        for page_num in range(pages):\n",
        "            try:\n",
        "                page_index = start_index - page_num\n",
        "                url = f\"https://www.ptt.cc/bbs/{board_name}/index{page_index}.html\"\n",
        "                print(f\"â³ æ­£åœ¨çˆ¬å–ç¬¬ {page_num + 1}/{pages} é : {url}\")\n",
        "\n",
        "                response = requests.get(url, headers=HEADERS, timeout=10)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "                article_list = soup.find_all('div', class_='r-ent')\n",
        "\n",
        "                for article in article_list:\n",
        "                    try:\n",
        "                        title_div = article.find('div', class_='title')\n",
        "                        title_tag = title_div.find('a') if title_div else None\n",
        "\n",
        "                        if title_tag and 'href' in title_tag.attrs:\n",
        "                            title = title_tag.text.strip()\n",
        "                            href = \"https://www.ptt.cc\" + title_tag['href']\n",
        "                        else:\n",
        "                            title = title_div.text.strip() if title_div else \"(ç„¡æ¨™é¡Œ)\"\n",
        "                            href = \"N/A\"\n",
        "\n",
        "                        author_div = article.find('div', class_='author')\n",
        "                        author = author_div.text.strip() if author_div else \"(åŒ¿å)\"\n",
        "\n",
        "                        date_div = article.find('div', class_='date')\n",
        "                        date = date_div.text.strip() if date_div else \"(ç„¡æ—¥æœŸ)\"\n",
        "\n",
        "                        articles_data.append({\n",
        "                            'title': title,\n",
        "                            'date': date,\n",
        "                            'author': author,\n",
        "                            'href': href,\n",
        "                            'page_index': page_index\n",
        "                        })\n",
        "                    except Exception as e:\n",
        "                        continue\n",
        "\n",
        "                print(f\"âœ… ç¬¬ {page_num + 1} é å®Œæˆï¼Œå–å¾— {len(article_list)} ç¯‡æ–‡ç« \")\n",
        "                time.sleep(delay)  # é¿å…è«‹æ±‚éå¿«\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âŒ ç¬¬ {page_num + 1} é çˆ¬å–å¤±æ•—: {e}\")\n",
        "                continue\n",
        "\n",
        "        print(f\"ğŸ‰ çˆ¬èŸ²å®Œæˆï¼å…±æ”¶é›† {len(articles_data)} ç¯‡æ–‡ç« \")\n",
        "        return pd.DataFrame(articles_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ çˆ¬èŸ²åˆå§‹åŒ–å¤±æ•—: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬ä¸‰éƒ¨åˆ†ï¼šGoogle Sheet è®€å¯«æ¨¡çµ„\n",
        "# ========================================\n",
        "\n",
        "def write_to_sheet(df, sheet_url, worksheet_name='çˆ¬èŸ²è³‡æ–™'):\n",
        "    \"\"\"å°‡ DataFrame å¯«å…¥ Google Sheet\"\"\"\n",
        "    try:\n",
        "        # é–‹å•Ÿè©¦ç®—è¡¨\n",
        "        try:\n",
        "            sh = gc.open_by_url(sheet_url)\n",
        "        except:\n",
        "            # å¦‚æœè©¦ç®—è¡¨ä¸å­˜åœ¨ï¼Œå‰µå»ºæ–°çš„\n",
        "            sh = gc.create(worksheet_name)\n",
        "            print(f\"ğŸ“ å·²å»ºç«‹æ–°è©¦ç®—è¡¨: {sh.url}\")\n",
        "\n",
        "        # æª¢æŸ¥å·¥ä½œè¡¨æ˜¯å¦å­˜åœ¨\n",
        "        try:\n",
        "            ws = sh.worksheet(worksheet_name)\n",
        "            ws.clear()  # æ¸…ç©ºç¾æœ‰è³‡æ–™\n",
        "        except:\n",
        "            ws = sh.add_worksheet(title=worksheet_name, rows=str(len(df)+10), cols=str(len(df.columns)+5))\n",
        "\n",
        "        # å¯«å…¥è³‡æ–™\n",
        "        ws.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "        print(f\"âœ… å·²å°‡ {len(df)} ç­†è³‡æ–™å¯«å…¥ã€Œ{worksheet_name}ã€å·¥ä½œè¡¨\")\n",
        "        return sh.url\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å¯«å…¥ Google Sheet å¤±æ•—: {e}\")\n",
        "        return None\n",
        "\n",
        "def read_from_sheet(sheet_url, worksheet_name='çˆ¬èŸ²è³‡æ–™'):\n",
        "    \"\"\"å¾ Google Sheet è®€å–è³‡æ–™\"\"\"\n",
        "    try:\n",
        "        sh = gc.open_by_url(sheet_url)\n",
        "        ws = sh.worksheet(worksheet_name)\n",
        "        df = pd.DataFrame(ws.get_all_records())\n",
        "        print(f\"âœ… å·²è®€å– {len(df)} ç­†è³‡æ–™\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ è®€å– Google Sheet å¤±æ•—: {e}\")\n",
        "        return None\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬å››éƒ¨åˆ†ï¼šä¸­æ–‡æ–·è©èˆ‡ TF-IDF åˆ†ææ¨¡çµ„\n",
        "# ========================================\n",
        "\n",
        "def analyze_text(df, text_column='title', topN=10):\n",
        "    \"\"\"\n",
        "    åŸ·è¡Œæ–‡æœ¬åˆ†æï¼šè©é »çµ±è¨ˆ + TF-IDF\n",
        "\n",
        "    åƒæ•¸:\n",
        "        df: DataFrame\n",
        "        text_column: è¦åˆ†æçš„æ–‡å­—æ¬„ä½\n",
        "        topN: å›å‚³å‰ N åçµæœ\n",
        "\n",
        "    å›å‚³:\n",
        "        tuple: (è©é »çµ±è¨ˆåˆ—è¡¨, TF-IDFæ’ååˆ—è¡¨)\n",
        "    \"\"\"\n",
        "    print(f\"\\nğŸ” é–‹å§‹åˆ†æã€Œ{text_column}ã€æ¬„ä½...\")\n",
        "\n",
        "    # éæ¿¾ç©ºå€¼\n",
        "    texts = df[text_column].dropna().astype(str).tolist()\n",
        "\n",
        "    if not texts:\n",
        "        print(\"âŒ æ²’æœ‰å¯åˆ†æçš„æ–‡å­—\")\n",
        "        return [], []\n",
        "\n",
        "    # === è©é »çµ±è¨ˆ ===\n",
        "    all_words = []\n",
        "    for text in texts:\n",
        "        # æ¸…ç†æ–‡å­—\n",
        "        cleaned_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        # æ–·è©\n",
        "        words = jieba.lcut(cleaned_text)\n",
        "        # éæ¿¾\n",
        "        filtered_words = [w.strip() for w in words\n",
        "                         if w.strip() and len(w.strip()) > 1 and w.strip() not in STOPWORDS]\n",
        "        all_words.extend(filtered_words)\n",
        "\n",
        "    freq_counter = Counter(all_words)\n",
        "    top_freq = freq_counter.most_common(topN)\n",
        "\n",
        "    print(f\"âœ… è©é »çµ±è¨ˆå®Œæˆï¼Œå…± {len(freq_counter)} å€‹ä¸é‡è¤‡è©å½™\")\n",
        "\n",
        "    # === TF-IDF åˆ†æ ===\n",
        "    try:\n",
        "        # æº–å‚™æ–‡æª”\n",
        "        documents = []\n",
        "        for text in texts:\n",
        "            cleaned_text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "            words = jieba.lcut(cleaned_text)\n",
        "            filtered_words = [w.strip() for w in words\n",
        "                             if w.strip() and len(w.strip()) > 1 and w.strip() not in STOPWORDS]\n",
        "            documents.append(\" \".join(filtered_words))\n",
        "\n",
        "        # è¨ˆç®— TF-IDF\n",
        "        vectorizer = TfidfVectorizer()\n",
        "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "        # è¨ˆç®—å¹³å‡æ¬Šé‡\n",
        "        avg_scores = tfidf_matrix.mean(axis=0).A1\n",
        "        tfidf_rank = sorted(zip(feature_names, avg_scores),\n",
        "                           key=lambda x: x[1], reverse=True)[:topN]\n",
        "\n",
        "        print(f\"âœ… TF-IDF åˆ†æå®Œæˆ\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ TF-IDF åˆ†æå¤±æ•—: {e}\")\n",
        "        tfidf_rank = []\n",
        "\n",
        "    return top_freq, tfidf_rank\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬äº”éƒ¨åˆ†ï¼šGemini AI æ‘˜è¦ç”Ÿæˆæ¨¡çµ„\n",
        "# ========================================\n",
        "\n",
        "def generate_gemini_summary(hot_words, sample_texts, analysis_type=\"æ–‡ç« æ¨™é¡Œ\"):\n",
        "    \"\"\"\n",
        "    ä½¿ç”¨ Gemini AI ç”Ÿæˆåˆ†ææ‘˜è¦\n",
        "\n",
        "    åƒæ•¸:\n",
        "        hot_words: ç†±é–€é—œéµè©åˆ—è¡¨\n",
        "        sample_texts: éƒ¨åˆ†æ–‡æœ¬æ¨£æœ¬\n",
        "        analysis_type: åˆ†æé¡å‹æè¿°\n",
        "\n",
        "    å›å‚³:\n",
        "        str: AI ç”Ÿæˆçš„æ‘˜è¦\n",
        "    \"\"\"\n",
        "    print(\"\\nğŸ¤– é–‹å§‹ç”Ÿæˆ Gemini AI æ‘˜è¦...\")\n",
        "\n",
        "    # æº–å‚™ prompt\n",
        "    hot_words_str = \"ã€\".join([f\"{word}({count}æ¬¡)\" for word, count in hot_words[:10]])\n",
        "    sample_str = \"\\n\".join([f\"- {text[:100]}\" for text in sample_texts[:5]])\n",
        "\n",
        "    prompt = f\"\"\"ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„è³‡æ–™åˆ†æå¸«ï¼Œè² è²¬åˆ†æ PTT è«–å£‡çš„{analysis_type}è³‡æ–™ã€‚\n",
        "\n",
        "**ç†±é–€é—œéµè©çµ±è¨ˆï¼š**\n",
        "{hot_words_str}\n",
        "\n",
        "**éƒ¨åˆ†{analysis_type}æ¨£æœ¬ï¼š**\n",
        "{sample_str}\n",
        "\n",
        "**è«‹é€²è¡Œä»¥ä¸‹åˆ†æï¼š**\n",
        "1. ç”¨5å¥è©±ç¸½çµç•¶å‰è¨è«–çš„ä¸»è¦è¶¨å‹¢èˆ‡ç¾è±¡\n",
        "2. æä¾›ä¸€æ®µ120å­—çš„ç¹é«”ä¸­æ–‡å°ˆæ¥­çµè«–æ‘˜è¦\n",
        "3. æŒ‡å‡ºè¨è«–çš„ç†±é»è©±é¡Œèˆ‡å€¼å¾—é—œæ³¨çš„æ–¹å‘\n",
        "\n",
        "è«‹ç›´æ¥æä¾›åˆ†æçµæœï¼Œä¸è¦åŒ…å«åˆ†ææ­¥é©Ÿèªªæ˜ã€‚ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”ã€‚\"\"\"\n",
        "\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        if hasattr(response, 'text'):\n",
        "            print(\"âœ… AI æ‘˜è¦ç”Ÿæˆå®Œæˆ\")\n",
        "            return response.text\n",
        "        else:\n",
        "            return \"âŒ AI ç„¡æ³•ç”Ÿæˆæ‘˜è¦\"\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"âŒ Gemini API å‘¼å«å¤±æ•—: {e}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬å…­éƒ¨åˆ†ï¼šçµ±è¨ˆçµæœå›å¯«æ¨¡çµ„\n",
        "# ========================================\n",
        "\n",
        "def write_analysis_to_sheet(freq_stats, tfidf_stats, ai_summary,\n",
        "                            sheet_url, worksheet_name='åˆ†æçµ±è¨ˆ'):\n",
        "    \"\"\"å°‡åˆ†æçµæœå›å¯«åˆ° Google Sheet\"\"\"\n",
        "    try:\n",
        "        sh = gc.open_by_url(sheet_url)\n",
        "\n",
        "        # å»ºç«‹æˆ–æ¸…ç©ºå·¥ä½œè¡¨\n",
        "        try:\n",
        "            ws = sh.worksheet(worksheet_name)\n",
        "            ws.clear()\n",
        "        except:\n",
        "            ws = sh.add_worksheet(title=worksheet_name, rows=\"100\", cols=\"10\")\n",
        "\n",
        "        # å¯«å…¥æ™‚é–“æˆ³è¨˜\n",
        "        from datetime import datetime\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "        ws.update('A1', [[f\"åˆ†æå ±å‘Š - ç”Ÿæˆæ™‚é–“ï¼š{timestamp}\"]])\n",
        "\n",
        "        # å¯«å…¥è©é »çµ±è¨ˆ\n",
        "        ws.update('A3', [[\"ğŸ“Š è©é »çµ±è¨ˆï¼ˆå‰10åï¼‰\", \"\", \"\"]])\n",
        "        ws.update('A4', [[\"æ’å\", \"é—œéµè©\", \"å‡ºç¾æ¬¡æ•¸\"]])\n",
        "        for i, (word, count) in enumerate(freq_stats[:10], start=1):\n",
        "            ws.update(f'A{4+i}', [[i, word, count]])\n",
        "\n",
        "        # å¯«å…¥ TF-IDF åˆ†æ\n",
        "        tfidf_start_row = 4 + len(freq_stats[:10]) + 3\n",
        "        ws.update(f'A{tfidf_start_row}', [[\"ğŸ“ˆ TF-IDF é‡è¦è©å½™åˆ†æ\", \"\"]])\n",
        "        ws.update(f'A{tfidf_start_row+1}', [[\"é—œéµè©\", \"TF-IDF åˆ†æ•¸\"]])\n",
        "        for i, (word, score) in enumerate(tfidf_stats[:10], start=1):\n",
        "            ws.update(f'A{tfidf_start_row+1+i}', [[word, round(score, 4)]])\n",
        "\n",
        "        # å¯«å…¥ AI æ‘˜è¦\n",
        "        summary_row = tfidf_start_row + len(tfidf_stats[:10]) + 4\n",
        "        ws.update(f'A{summary_row}', [[\"ğŸ¤– Gemini AI æ·±åº¦æ´å¯Ÿåˆ†æ\"]])\n",
        "        ws.update(f'A{summary_row+1}', [[ai_summary]])\n",
        "\n",
        "        print(f\"âœ… çµ±è¨ˆçµæœå·²å¯«å…¥ã€Œ{worksheet_name}ã€å·¥ä½œè¡¨\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ å›å¯«çµ±è¨ˆå¤±æ•—: {e}\")\n",
        "        return False\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå®Œæ•´æµç¨‹æ•´åˆ\n",
        "# ========================================\n",
        "\n",
        "def full_automation_pipeline(board_name, pages, topN, sheet_url=None):\n",
        "    \"\"\"\n",
        "    å®Œæ•´è‡ªå‹•åŒ–æµç¨‹ï¼šçˆ¬èŸ² â†’ Sheet â†’ åˆ†æ â†’ AI â†’ å›å¯«\n",
        "\n",
        "    åƒæ•¸:\n",
        "        board_name: PTT çœ‹æ¿åç¨±\n",
        "        pages: çˆ¬å–é æ•¸\n",
        "        topN: é¡¯ç¤ºå‰ N åé—œéµè©\n",
        "        sheet_url: Google Sheet URL (å¯é¸)\n",
        "\n",
        "    å›å‚³:\n",
        "        str: åŸ·è¡Œçµæœå ±å‘Š\n",
        "    \"\"\"\n",
        "    report = []\n",
        "    report.append(\"=\" * 60)\n",
        "    report.append(\"ğŸš€ PTT çˆ¬èŸ²èˆ‡æ–‡æœ¬åˆ†æç³»çµ± - åŸ·è¡Œé–‹å§‹\")\n",
        "    report.append(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    try:\n",
        "        # ===== æ­¥é©Ÿ 1: çˆ¬å– PTT è³‡æ–™ =====\n",
        "        report.append(\"ğŸ“ æ­¥é©Ÿ 1/5ï¼šçˆ¬å– PTT è³‡æ–™\")\n",
        "        df_articles = crawl_ptt_board(board_name=board_name, pages=pages, delay=1)\n",
        "\n",
        "        if df_articles.empty:\n",
        "            return \"\\n\".join(report) + \"\\nâŒ çˆ¬èŸ²å¤±æ•—ï¼Œç„¡æ³•ç¹¼çºŒåŸ·è¡Œ\"\n",
        "\n",
        "        report.append(f\"âœ… æˆåŠŸçˆ¬å– {len(df_articles)} ç¯‡æ–‡ç« \\n\")\n",
        "\n",
        "        # ===== æ­¥é©Ÿ 2: å¯«å…¥ Google Sheet =====\n",
        "        report.append(\"ğŸ“ æ­¥é©Ÿ 2/5ï¼šå¯«å…¥ Google Sheet\")\n",
        "        if not sheet_url:\n",
        "            # å‰µå»ºæ–°è©¦ç®—è¡¨\n",
        "            new_sheet = gc.create(f'PTT_{board_name}_åˆ†æ')\n",
        "            sheet_url = new_sheet.url\n",
        "            report.append(f\"ğŸ“ å·²å»ºç«‹æ–°è©¦ç®—è¡¨ï¼š{sheet_url}\")\n",
        "\n",
        "        result_url = write_to_sheet(df_articles, sheet_url, worksheet_name='çˆ¬èŸ²è³‡æ–™')\n",
        "        if result_url:\n",
        "            report.append(f\"âœ… è³‡æ–™å·²å¯«å…¥ï¼š{result_url}\\n\")\n",
        "        else:\n",
        "            report.append(\"âš ï¸ å¯«å…¥å¤±æ•—ï¼Œä½†ç¹¼çºŒåŸ·è¡Œåˆ†æ\\n\")\n",
        "\n",
        "        # ===== æ­¥é©Ÿ 3: å¾ Sheet è®€å–ä¸¦åˆ†æ =====\n",
        "        report.append(\"ğŸ“ æ­¥é©Ÿ 3/5ï¼šæ–‡æœ¬åˆ†æï¼ˆè©é » + TF-IDFï¼‰\")\n",
        "        freq_stats, tfidf_stats = analyze_text(df_articles, text_column='title', topN=topN)\n",
        "\n",
        "        if freq_stats:\n",
        "            report.append(f\"âœ… åˆ†æå®Œæˆï¼Œç™¼ç¾ {len(freq_stats)} å€‹ç†±é–€è©å½™\\n\")\n",
        "        else:\n",
        "            return \"\\n\".join(report) + \"\\nâŒ åˆ†æå¤±æ•—\"\n",
        "\n",
        "        # ===== æ­¥é©Ÿ 4: Gemini AI ç”Ÿæˆæ‘˜è¦ =====\n",
        "        report.append(\"ğŸ“ æ­¥é©Ÿ 4/5ï¼šGemini AI ç”Ÿæˆæ´å¯Ÿæ‘˜è¦\")\n",
        "        sample_texts = df_articles['title'].dropna().astype(str).tolist()\n",
        "        ai_summary = generate_gemini_summary(freq_stats, sample_texts, analysis_type=\"æ–‡ç« æ¨™é¡Œ\")\n",
        "        report.append(\"âœ… AI æ‘˜è¦ç”Ÿæˆå®Œæˆ\\n\")\n",
        "\n",
        "        # ===== æ­¥é©Ÿ 5: å›å¯«çµ±è¨ˆçµæœ =====\n",
        "        report.append(\"ğŸ“ æ­¥é©Ÿ 5/5ï¼šå›å¯«åˆ†æçµ±è¨ˆ\")\n",
        "        if sheet_url:\n",
        "            write_analysis_to_sheet(freq_stats, tfidf_stats, ai_summary,\n",
        "                                   sheet_url, worksheet_name='åˆ†æçµ±è¨ˆ')\n",
        "            report.append(f\"âœ… çµ±è¨ˆçµæœå·²å›å¯«è‡³è©¦ç®—è¡¨\\n\")\n",
        "\n",
        "        # ===== ç”Ÿæˆæœ€çµ‚å ±å‘Š =====\n",
        "        report.append(\"=\" * 60)\n",
        "        report.append(\"ğŸ“Š åˆ†æçµæœæ‘˜è¦\")\n",
        "        report.append(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "        # ç†±é–€é—œéµè©\n",
        "        report.append(\"### ğŸ”¥ ç†±é–€é—œéµè©çµ±è¨ˆï¼ˆå‰10åï¼‰\")\n",
        "        for i, (word, count) in enumerate(freq_stats[:10], 1):\n",
        "            report.append(f\"{i}. **{word}** - {count} æ¬¡\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # TF-IDF é‡è¦è©å½™\n",
        "        report.append(\"### ğŸ“ˆ TF-IDF é‡è¦è©å½™ï¼ˆå‰10åï¼‰\")\n",
        "        for i, (word, score) in enumerate(tfidf_stats[:10], 1):\n",
        "            report.append(f\"{i}. **{word}** - {score:.4f}\")\n",
        "        report.append(\"\")\n",
        "\n",
        "        # AI æ´å¯Ÿ\n",
        "        report.append(\"### ğŸ¤– Gemini AI æ·±åº¦æ´å¯Ÿ\")\n",
        "        report.append(ai_summary)\n",
        "        report.append(\"\")\n",
        "\n",
        "        # è³‡æ–™æ¦‚è¦½\n",
        "        report.append(\"### ğŸ“‹ è³‡æ–™æ¦‚è¦½\")\n",
        "        report.append(f\"- çœ‹æ¿åç¨±ï¼š**{board_name}**\")\n",
        "        report.append(f\"- æ–‡ç« æ•¸é‡ï¼š**{len(df_articles)}** ç¯‡\")\n",
        "        report.append(f\"- åˆ†ææ™‚é–“ï¼š**{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}**\")\n",
        "        if sheet_url:\n",
        "            report.append(f\"- Google Sheetï¼š[é»æ­¤æŸ¥çœ‹]({sheet_url})\")\n",
        "\n",
        "        report.append(\"\\n\" + \"=\" * 60)\n",
        "        report.append(\"ğŸ‰ æ‰€æœ‰æµç¨‹åŸ·è¡Œå®Œæˆï¼\")\n",
        "        report.append(\"=\" * 60)\n",
        "\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "    except Exception as e:\n",
        "        report.append(f\"\\nâŒ åŸ·è¡Œéç¨‹ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\")\n",
        "        return \"\\n\".join(report)\n",
        "\n",
        "# ========================================\n",
        "# ç¬¬å…«éƒ¨åˆ†ï¼šGradio UI ä»‹é¢\n",
        "# ========================================\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"å»ºç«‹ Gradio ä½¿ç”¨è€…ä»‹é¢\"\"\"\n",
        "\n",
        "    with gr.Blocks(theme=gr.themes.Soft(), title=\"PTT çˆ¬èŸ²åˆ†æç³»çµ±\") as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ğŸ¯ PTT çˆ¬èŸ²èˆ‡æ–‡æœ¬åˆ†æç³»çµ±\n",
        "        **å®Œæ•´è‡ªå‹•åŒ–æµç¨‹ï¼š** PTTçˆ¬èŸ² â†’ Google Sheet â†’ ä¸­æ–‡æ–·è© â†’ TF-IDFåˆ†æ â†’ Gemini AIæ´å¯Ÿ â†’ çµ±è¨ˆå›å¯«\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                gr.Markdown(\"### ğŸ“ åƒæ•¸è¨­å®š\")\n",
        "                board_input = gr.Textbox(\n",
        "                    label=\"ğŸ¬ PTT çœ‹æ¿åç¨±\",\n",
        "                    value=\"movie\",\n",
        "                    placeholder=\"ä¾‹å¦‚ï¼šmovie, Gossiping, Tech_Job\",\n",
        "                    info=\"è¼¸å…¥è¦çˆ¬å–çš„ PTT çœ‹æ¿åç¨±\"\n",
        "                )\n",
        "                pages_input = gr.Slider(\n",
        "                    minimum=1,\n",
        "                    maximum=20,\n",
        "                    value=5,\n",
        "                    step=1,\n",
        "                    label=\"ğŸ“„ çˆ¬å–é æ•¸\",\n",
        "                    info=\"æ¯é ç´„ 20 ç¯‡æ–‡ç« \"\n",
        "                )\n",
        "                topN_input = gr.Slider(\n",
        "                    minimum=5,\n",
        "                    maximum=30,\n",
        "                    value=10,\n",
        "                    step=1,\n",
        "                    label=\"ğŸ”¢ é¡¯ç¤ºå‰ N åé—œéµè©\"\n",
        "                )\n",
        "                sheet_url_input = gr.Textbox(\n",
        "                    label=\"ğŸ”— Google Sheet URLï¼ˆé¸å¡«ï¼‰\",\n",
        "                    placeholder=\"ç•™ç©ºå‰‡è‡ªå‹•å»ºç«‹æ–°è©¦ç®—è¡¨\",\n",
        "                    info=\"è‹¥è¦ä½¿ç”¨ç¾æœ‰è©¦ç®—è¡¨ï¼Œè«‹è²¼ä¸Šå®Œæ•´ URL\"\n",
        "                )\n",
        "\n",
        "                submit_btn = gr.Button(\n",
        "                    \"ğŸš€ é–‹å§‹åŸ·è¡Œå®Œæ•´åˆ†æ\",\n",
        "                    variant=\"primary\",\n",
        "                    size=\"lg\"\n",
        "                )\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"### ğŸ“Š åŸ·è¡Œçµæœ\")\n",
        "                output_box = gr.Textbox(\n",
        "                    label=\"åˆ†æå ±å‘Š\",\n",
        "                    lines=25,\n",
        "                    max_lines=30,\n",
        "                    show_copy_button=True\n",
        "                )\n",
        "\n",
        "        # æŒ‰éˆ•äº‹ä»¶ç¶å®š\n",
        "        submit_btn.click(\n",
        "            fn=full_automation_pipeline,\n",
        "            inputs=[board_input, pages_input, topN_input, sheet_url_input],\n",
        "            outputs=output_box\n",
        "        )\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "        ### ğŸ“Œ ä½¿ç”¨èªªæ˜\n",
        "        1. **Gemini API Key**ï¼šè«‹å…ˆåœ¨ç¨‹å¼ç¢¼ä¸­å¡«å…¥æ‚¨çš„ API Keyï¼ˆå‰å¾€ [Google AI Studio](https://makersuite.google.com/app/apikey) ç”³è«‹ï¼‰\n",
        "        2. **çœ‹æ¿åç¨±**ï¼šè¼¸å…¥è¦åˆ†æçš„ PTT çœ‹æ¿ï¼ˆä¾‹å¦‚ï¼šmovieã€Gossipingã€Stockï¼‰\n",
        "        3. **é æ•¸è¨­å®š**ï¼šå»ºè­° 5-10 é ï¼Œé¿å…çˆ¬å–éå¤šå°è‡´åŸ·è¡Œæ™‚é–“éé•·\n",
        "        4. **åŸ·è¡Œæµç¨‹**ï¼šé»æ“Šã€Œé–‹å§‹åŸ·è¡Œã€å¾Œï¼Œç³»çµ±æœƒè‡ªå‹•å®Œæˆæ‰€æœ‰æ­¥é©Ÿ\n",
        "        5. **æŸ¥çœ‹çµæœ**ï¼šåˆ†æå®Œæˆå¾Œæœƒåœ¨å³å´é¡¯ç¤ºå ±å‘Šï¼Œä¸¦è‡ªå‹•å¯«å…¥ Google Sheet\n",
        "\n",
        "        ### âš ï¸ æ³¨æ„äº‹é …\n",
        "        - è«‹éµå®ˆ PTT ä½¿ç”¨è¦ç¯„ï¼Œé©åº¦ä½¿ç”¨çˆ¬èŸ²åŠŸèƒ½\n",
        "        - çˆ¬å–é€Ÿåº¦å·²è¨­å®šå»¶é²ï¼Œé¿å…å°ä¼ºæœå™¨é€ æˆè² æ“”\n",
        "        - ç¢ºä¿å·²å®Œæˆ Google Colab çš„æˆæ¬Šèªè­‰\n",
        "        - Gemini API æœ‰ä½¿ç”¨é¡åº¦é™åˆ¶ï¼Œè«‹æ³¨æ„é…é¡ä½¿ç”¨ç‹€æ³\n",
        "\n",
        "        ### ğŸ”§ ç³»çµ±æ¶æ§‹\n",
        "        | æ¨¡çµ„ | æŠ€è¡“ | åŠŸèƒ½ |\n",
        "        |------|------|------|\n",
        "        | çˆ¬èŸ² | requests + BeautifulSoup | æ‰¹æ¬¡çˆ¬å–æ–‡ç« è³‡æ–™ |\n",
        "        | å„²å­˜ | gspread + OAuth2 | Google Sheet è®€å¯« |\n",
        "        | æ–·è© | jieba | ä¸­æ–‡æ–‡æœ¬æ–·è© |\n",
        "        | åˆ†æ | scikit-learn TF-IDF | é—œéµè©æå– |\n",
        "        | AI | Gemini API | æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ |\n",
        "        | UI | Gradio | äº’å‹•å¼ä»‹é¢ |\n",
        "        \"\"\")\n",
        "\n",
        "    return demo\n",
        "\n",
        "# ========================================\n",
        "# ä¸»ç¨‹å¼åŸ·è¡Œå€\n",
        "# ========================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸ¯ PTT çˆ¬èŸ²èˆ‡æ–‡æœ¬åˆ†æç³»çµ±\")\n",
        "    print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    # å•Ÿå‹• Gradio ä»‹é¢\n",
        "    demo = create_gradio_interface()\n",
        "    demo.launch(\n",
        "        share=True,  # ç”¢ç”Ÿå…¬é–‹é€£çµ\n",
        "        debug=True   # é–‹å•Ÿé™¤éŒ¯æ¨¡å¼\n",
        "    )\n",
        "\n",
        "    print(\"\\nâœ… Gradio ä»‹é¢å·²å•Ÿå‹•\")\n",
        "    print(\"ğŸ“± å¯é€éç”¢ç”Ÿçš„é€£çµåœ¨ä»»ä½•è£ç½®ä¸Šä½¿ç”¨\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8MrqifIuwmSh",
        "outputId": "bfb0f9c8-9868-487d-f2d3-6fdd19462bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… å‡½å¼åº«è¼‰å…¥å®Œæˆ\n",
            "âœ… èªè­‰èˆ‡è¨­å®šå®Œæˆ\n",
            "\n",
            "============================================================\n",
            "ğŸ¯ PTT çˆ¬èŸ²èˆ‡æ–‡æœ¬åˆ†æç³»çµ±\n",
            "============================================================\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://69a63e355eae9babf8.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://69a63e355eae9babf8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸš€ é–‹å§‹çˆ¬å– PTT movie ç‰ˆï¼Œå¾ç¬¬ 10809 é é–‹å§‹\n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 1/5 é : https://www.ptt.cc/bbs/movie/index10809.html\n",
            "âœ… ç¬¬ 1 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 2/5 é : https://www.ptt.cc/bbs/movie/index10808.html\n",
            "âœ… ç¬¬ 2 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 3/5 é : https://www.ptt.cc/bbs/movie/index10807.html\n",
            "âœ… ç¬¬ 3 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 4/5 é : https://www.ptt.cc/bbs/movie/index10806.html\n",
            "âœ… ç¬¬ 4 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 5/5 é : https://www.ptt.cc/bbs/movie/index10805.html\n",
            "âœ… ç¬¬ 5 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "ğŸ‰ çˆ¬èŸ²å®Œæˆï¼å…±æ”¶é›† 100 ç¯‡æ–‡ç« \n",
            "âœ… å·²å°‡ 100 ç­†è³‡æ–™å¯«å…¥ã€Œçˆ¬èŸ²è³‡æ–™ã€å·¥ä½œè¡¨\n",
            "\n",
            "ğŸ” é–‹å§‹åˆ†æã€Œtitleã€æ¬„ä½...\n",
            "âœ… è©é »çµ±è¨ˆå®Œæˆï¼Œå…± 428 å€‹ä¸é‡è¤‡è©å½™\n",
            "âœ… TF-IDF åˆ†æå®Œæˆ\n",
            "\n",
            "ğŸ¤– é–‹å§‹ç”Ÿæˆ Gemini AI æ‘˜è¦...\n",
            "âœ… AI æ‘˜è¦ç”Ÿæˆå®Œæˆ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3374716129.py:340: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A1', [[f\"åˆ†æå ±å‘Š - ç”Ÿæˆæ™‚é–“ï¼š{timestamp}\"]])\n",
            "/tmp/ipython-input-3374716129.py:343: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A3', [[\"ğŸ“Š è©é »çµ±è¨ˆï¼ˆå‰10åï¼‰\", \"\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:344: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A4', [[\"æ’å\", \"é—œéµè©\", \"å‡ºç¾æ¬¡æ•¸\"]])\n",
            "/tmp/ipython-input-3374716129.py:346: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{4+i}', [[i, word, count]])\n",
            "/tmp/ipython-input-3374716129.py:350: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row}', [[\"ğŸ“ˆ TF-IDF é‡è¦è©å½™åˆ†æ\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:351: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1}', [[\"é—œéµè©\", \"TF-IDF åˆ†æ•¸\"]])\n",
            "/tmp/ipython-input-3374716129.py:353: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1+i}', [[word, round(score, 4)]])\n",
            "/tmp/ipython-input-3374716129.py:357: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row}', [[\"ğŸ¤– Gemini AI æ·±åº¦æ´å¯Ÿåˆ†æ\"]])\n",
            "/tmp/ipython-input-3374716129.py:358: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row+1}', [[ai_summary]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… çµ±è¨ˆçµæœå·²å¯«å…¥ã€Œåˆ†æçµ±è¨ˆã€å·¥ä½œè¡¨\n",
            "ğŸš€ é–‹å§‹çˆ¬å– PTT movie ç‰ˆï¼Œå¾ç¬¬ 10809 é é–‹å§‹\n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 1/5 é : https://www.ptt.cc/bbs/movie/index10809.html\n",
            "âœ… ç¬¬ 1 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 2/5 é : https://www.ptt.cc/bbs/movie/index10808.html\n",
            "âœ… ç¬¬ 2 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 3/5 é : https://www.ptt.cc/bbs/movie/index10807.html\n",
            "âœ… ç¬¬ 3 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 4/5 é : https://www.ptt.cc/bbs/movie/index10806.html\n",
            "âœ… ç¬¬ 4 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "â³ æ­£åœ¨çˆ¬å–ç¬¬ 5/5 é : https://www.ptt.cc/bbs/movie/index10805.html\n",
            "âœ… ç¬¬ 5 é å®Œæˆï¼Œå–å¾— 20 ç¯‡æ–‡ç« \n",
            "ğŸ‰ çˆ¬èŸ²å®Œæˆï¼å…±æ”¶é›† 100 ç¯‡æ–‡ç« \n",
            "âœ… å·²å°‡ 100 ç­†è³‡æ–™å¯«å…¥ã€Œçˆ¬èŸ²è³‡æ–™ã€å·¥ä½œè¡¨\n",
            "\n",
            "ğŸ” é–‹å§‹åˆ†æã€Œtitleã€æ¬„ä½...\n",
            "âœ… è©é »çµ±è¨ˆå®Œæˆï¼Œå…± 428 å€‹ä¸é‡è¤‡è©å½™\n",
            "âœ… TF-IDF åˆ†æå®Œæˆ\n",
            "\n",
            "ğŸ¤– é–‹å§‹ç”Ÿæˆ Gemini AI æ‘˜è¦...\n",
            "âœ… AI æ‘˜è¦ç”Ÿæˆå®Œæˆ\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3374716129.py:340: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A1', [[f\"åˆ†æå ±å‘Š - ç”Ÿæˆæ™‚é–“ï¼š{timestamp}\"]])\n",
            "/tmp/ipython-input-3374716129.py:343: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A3', [[\"ğŸ“Š è©é »çµ±è¨ˆï¼ˆå‰10åï¼‰\", \"\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:344: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update('A4', [[\"æ’å\", \"é—œéµè©\", \"å‡ºç¾æ¬¡æ•¸\"]])\n",
            "/tmp/ipython-input-3374716129.py:346: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{4+i}', [[i, word, count]])\n",
            "/tmp/ipython-input-3374716129.py:350: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row}', [[\"ğŸ“ˆ TF-IDF é‡è¦è©å½™åˆ†æ\", \"\"]])\n",
            "/tmp/ipython-input-3374716129.py:351: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1}', [[\"é—œéµè©\", \"TF-IDF åˆ†æ•¸\"]])\n",
            "/tmp/ipython-input-3374716129.py:353: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{tfidf_start_row+1+i}', [[word, round(score, 4)]])\n",
            "/tmp/ipython-input-3374716129.py:357: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row}', [[\"ğŸ¤– Gemini AI æ·±åº¦æ´å¯Ÿåˆ†æ\"]])\n",
            "/tmp/ipython-input-3374716129.py:358: DeprecationWarning: The order of arguments in worksheet.update() has changed. Please pass values first and range_name secondor used named arguments (range_name=, values=)\n",
            "  ws.update(f'A{summary_row+1}', [[ai_summary]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… çµ±è¨ˆçµæœå·²å¯«å…¥ã€Œåˆ†æçµ±è¨ˆã€å·¥ä½œè¡¨\n"
          ]
        }
      ]
    }
  ]
}