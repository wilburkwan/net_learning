import torch
from transformers import AutoTokenizer, AutoModel
from qdrant_client import QdrantClient
from qdrant_client.http.models import Filter, FieldCondition, MatchAny

from jubollm.nCopilot.searcher.base_searcher import BaseSearcher

model_name = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)


class QdrantSearcher(BaseSearcher):
    def __init__(self, db):
        super().__init__(db)
        self.client = QdrantClient(url=self.db)
        self.collection_name = "table_info_collection"

    def encode_txt_to_vector(self, text):
        inputs = tokenizer(
            text,
            return_tensors='pt',
            max_length=512,
            truncation=True,
            padding='max_length'
        )
        with torch.no_grad():
            outputs = model(**inputs)
        return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()

    def query_qdrant(self, vector, vector_name, limit, filter_conditions=None):
        # Convert input sentence to vector
        query_vector = vector.tolist()
        
        # Build filter if conditions are provided
        search_filter = None
        if filter_conditions:
            must_conditions = []
            for key, value in filter_conditions.items():
                must_conditions.append(FieldCondition(
                    key=key, match=MatchAny(any=value)))
            search_filter = Filter(must=must_conditions)

            search_result = self.client.search(
                collection_name=self.collection_name,
                query_filter=search_filter,
                query_vector=(f"{vector_name}", query_vector),
                limit=limit
            )
            return search_result
        # # Create search request
        # search_request = SearchRequest(
        #     vector=query_vector,
        #     limit=5,  # Number of closest points to return
        #     filter=search_filter
        # )

        # Perform search
        search_result = self.client.search(
            collection_name=self.collection_name, query_vector=(f"{vector_name}", query_vector), limit=limit)
        return search_result

    def get_table_columns_from_qdrant(self, vector):
        results = self.query_qdrant(vector, vector_name="Table", limit=20, filter_conditions=None)
        ranking_name = []
        re_ranking_id = []
        for result in results:
            # print(
            #    f"ID: {result.id} | Score: {result.score:.4f} | Table Name: {result.payload['table_name']} | Table Description: {result.payload['table_description']}")
            ranking_name.append(result.payload['table_name'])
            re_ranking_id.append(result.id)
        second_condition = {"table_name": ranking_name}
        second_results = self.query_qdrant(vector, vector_name="Column", limit=3, filter_conditions=second_condition)
        
        # 將第二層的結果按照第一層的排序重新排列
        second_results_id = [i.id for i in second_results]
        sorted_second_result = [second_results[second_results_id.index(i)] for i in re_ranking_id if i in second_results_id]
        second_result = sorted_second_result[0]
        # print(f"ID: {second_result.id} | Table Name: {second_result.payload['table_name']} | Score: {second_result.score:.4f}")
        
        columns_description = {}
        for column_name, column_info in second_result.payload['columns'].items():
            columns_description[column_name] = column_info['description']

        return second_result.payload['table_name'], columns_description
